{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Analysis\n",
    "Download dataset here:\n",
    "- https://www.kaggle.com/hacker-news/hacker-news-posts\n",
    "\n",
    "Other:\n",
    "- [Python's strftime directives](https://strftime.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function **explore_data** prints selected rows for a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function **explore_data** prints selected rows for a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_list(filename):\n",
    "    opened_file = open(filename)\n",
    "    from csv import reader\n",
    "    read_file = reader(opened_file)\n",
    "    return list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "**hacker_news.csv**\n",
    "\n",
    "| Column name | Description |\n",
    "| ----------- | ----------- |\n",
    "| 'id' | The unique identifier from Hacker News for the post |\n",
    "| 'title' | The title of the post |\n",
    "| 'url' | The URL that the posts links to, if it the post has a URL |\n",
    "| 'num_points' | The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes |\n",
    "| 'num_comments' | The number of comments that were made on the post |\n",
    "| 'author' | The username of the person who submitted the post |\n",
    "| 'created_at' | The date and time at which the post was submitted |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = get_csv_list('/Users/robdurkin/dev/Dataquest/projects/datasets/hacker_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n",
      "Number of rows: 293120\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "explore_data(hn, 0, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_data(hn, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data\n",
    "Get posts with titles of **Ask HN** or **Show HN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ask Posts: 9139\n",
      "# Show Posts: 10158\n",
      "# Other Posts: 273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts, show_posts, other_posts = [], [], []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        \n",
    "print('# Ask Posts: {}'.format(len(ask_posts)))\n",
    "print('# Show Posts: {}'.format(len(show_posts)))\n",
    "print('# Other Posts: {}'.format(len(other_posts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do \"Ask HN\" or \"Show HN\" receive more comments on average?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # ask comments: 94,986\n",
      "Average # ask comments: 10.39\n",
      "Total # show comments: 49,633\n",
      "Average # show comments: 4.89\n",
      "Total # other comments: 1,768,142\n",
      "Average # other comments: 6.46\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for post in ask_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_ask_comments += num_comments\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print('Total # ask comments: {:,}'.format(total_ask_comments))\n",
    "print('Average # ask comments: {:.2f}'.format(avg_ask_comments))\n",
    "\n",
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print('Total # show comments: {:,}'.format(total_show_comments))\n",
    "print('Average # show comments: {:.2f}'.format(avg_show_comments))\n",
    "\n",
    "total_other_comments = 0\n",
    "for post in other_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_other_comments += num_comments\n",
    "avg_other_comments = total_other_comments / len(other_posts)\n",
    "\n",
    "print('Total # other comments: {:,}'.format(total_other_comments))\n",
    "print('Average # other comments: {:.2f}'.format(avg_other_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: \"Ask HN\" posts receive more comments than \"Show HN\" posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are \"Ask HN\" posts created at a certain time more likely to attract comments?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Posts and # Comments by Hour\n",
      "\n",
      "Hour: 00, # Posts: 301, # Comments: 2277\n",
      "Hour: 01, # Posts: 282, # Comments: 2089\n",
      "Hour: 02, # Posts: 269, # Comments: 2996\n",
      "Hour: 03, # Posts: 271, # Comments: 2154\n",
      "Hour: 04, # Posts: 243, # Comments: 2360\n",
      "Hour: 05, # Posts: 209, # Comments: 1838\n",
      "Hour: 06, # Posts: 234, # Comments: 1587\n",
      "Hour: 07, # Posts: 226, # Comments: 1585\n",
      "Hour: 08, # Posts: 257, # Comments: 2362\n",
      "Hour: 09, # Posts: 222, # Comments: 1477\n",
      "Hour: 10, # Posts: 282, # Comments: 3013\n",
      "Hour: 11, # Posts: 312, # Comments: 2797\n",
      "Hour: 12, # Posts: 342, # Comments: 4234\n",
      "Hour: 13, # Posts: 444, # Comments: 7245\n",
      "Hour: 14, # Posts: 513, # Comments: 4972\n",
      "Hour: 15, # Posts: 646, # Comments: 18525\n",
      "Hour: 16, # Posts: 579, # Comments: 4466\n",
      "Hour: 17, # Posts: 587, # Comments: 5547\n",
      "Hour: 18, # Posts: 614, # Comments: 4877\n",
      "Hour: 19, # Posts: 552, # Comments: 3954\n",
      "Hour: 20, # Posts: 510, # Comments: 4462\n",
      "Hour: 21, # Posts: 518, # Comments: 4500\n",
      "Hour: 22, # Posts: 383, # Comments: 3372\n",
      "Hour: 23, # Posts: 343, # Comments: 2297\n",
      "\n",
      "\n",
      "Sorted by # Comments Per Hour\n",
      "\n",
      "Hour: 15, # Comments: 18525\n",
      "Hour: 13, # Comments: 7245\n",
      "Hour: 17, # Comments: 5547\n",
      "Hour: 14, # Comments: 4972\n",
      "Hour: 18, # Comments: 4877\n",
      "Hour: 21, # Comments: 4500\n",
      "Hour: 16, # Comments: 4466\n",
      "Hour: 20, # Comments: 4462\n",
      "Hour: 12, # Comments: 4234\n",
      "Hour: 19, # Comments: 3954\n",
      "Hour: 22, # Comments: 3372\n",
      "Hour: 10, # Comments: 3013\n",
      "Hour: 02, # Comments: 2996\n",
      "Hour: 11, # Comments: 2797\n",
      "Hour: 08, # Comments: 2362\n",
      "Hour: 04, # Comments: 2360\n",
      "Hour: 23, # Comments: 2297\n",
      "Hour: 00, # Comments: 2277\n",
      "Hour: 03, # Comments: 2154\n",
      "Hour: 01, # Comments: 2089\n",
      "Hour: 05, # Comments: 1838\n",
      "Hour: 06, # Comments: 1587\n",
      "Hour: 07, # Comments: 1585\n",
      "Hour: 09, # Comments: 1477\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for post in ask_posts:\n",
    "    item = [post[6], int(post[4])]\n",
    "    result_list.append(item)\n",
    "    \n",
    "    \n",
    "posts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for result in result_list:\n",
    "    created_at = result[0]\n",
    "    created_dt = dt.datetime.strptime(created_at, \"%m/%d/%Y %H:%M\")\n",
    "    hour =  dt.datetime.strftime(created_dt, \"%H\")\n",
    "\n",
    "    num_comments = result[1]\n",
    "    if hour not in posts_by_hour:\n",
    "        posts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = num_comments\n",
    "    else:\n",
    "        posts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += num_comments\n",
    "    \n",
    "print(\"# Posts and # Comments by Hour\\n\")    \n",
    "num_comments_hour = []   \n",
    "for hour in sorted(posts_by_hour):\n",
    "    num_comments_hour.append((hour,comments_by_hour[hour])) \n",
    "    print(\"Hour: {}, # Posts: {}, # Comments: {}\"\n",
    "        .format(hour, posts_by_hour[hour], comments_by_hour[hour]))\n",
    "    \n",
    "print(\"\\n\\nSorted by # Comments Per Hour\\n\")\n",
    "for item in sorted(num_comments_hour, key = lambda x: x[1], reverse = True):\n",
    "    print(\"Hour: {}, # Comments: {}\"\n",
    "        .format(item[0], item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: Comments are more likely for \"Ask HN\" posts between the hours of 1300 and 1800, with a peak at 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of comments per post by hour (sorted by hour)\n",
      "Hour: 00, Avg # Comments: 7.56\n",
      "Hour: 01, Avg # Comments: 7.41\n",
      "Hour: 02, Avg # Comments: 11.14\n",
      "Hour: 03, Avg # Comments: 7.95\n",
      "Hour: 04, Avg # Comments: 9.71\n",
      "Hour: 05, Avg # Comments: 8.79\n",
      "Hour: 06, Avg # Comments: 6.78\n",
      "Hour: 07, Avg # Comments: 7.01\n",
      "Hour: 08, Avg # Comments: 9.19\n",
      "Hour: 09, Avg # Comments: 6.65\n",
      "Hour: 10, Avg # Comments: 10.68\n",
      "Hour: 11, Avg # Comments: 8.96\n",
      "Hour: 12, Avg # Comments: 12.38\n",
      "Hour: 13, Avg # Comments: 16.32\n",
      "Hour: 14, Avg # Comments: 9.69\n",
      "Hour: 15, Avg # Comments: 28.68\n",
      "Hour: 16, Avg # Comments: 7.71\n",
      "Hour: 17, Avg # Comments: 9.45\n",
      "Hour: 18, Avg # Comments: 7.94\n",
      "Hour: 19, Avg # Comments: 7.16\n",
      "Hour: 20, Avg # Comments: 8.75\n",
      "Hour: 21, Avg # Comments: 8.69\n",
      "Hour: 22, Avg # Comments: 8.80\n",
      "Hour: 23, Avg # Comments: 6.70\n",
      "\n",
      "\n",
      "Top 5 Average number of comments per post by hour (sorted by # comments)\n",
      "Hour: 15, Avg # Comments: 28.68\n",
      "Hour: 13, Avg # Comments: 16.32\n",
      "Hour: 12, Avg # Comments: 12.38\n",
      "Hour: 02, Avg # Comments: 11.14\n",
      "Hour: 10, Avg # Comments: 10.68\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour, swap_avg_by_hour = [],[]\n",
    "for hour in posts_by_hour:\n",
    "    num_posts = posts_by_hour[hour]\n",
    "    avg_num_posts = comments_by_hour[hour] / num_posts\n",
    "    avg_by_hour.append([hour, avg_num_posts])\n",
    "    swap_avg_by_hour.append([avg_num_posts, hour])\n",
    "    \n",
    "print(\"Average number of comments per post by hour (sorted by hour)\")\n",
    "for rec in sorted(avg_by_hour):\n",
    "    hour = rec[0]\n",
    "    avg = rec[1]\n",
    "    print(\"Hour: {}, Avg # Comments: {:.2f}\".format(hour, avg))\n",
    "    \n",
    "print(\"\\n\\nTop 5 Average number of comments per post by hour (sorted by # comments)\")\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "for rec in sorted_swap[:5]:\n",
    "    print(\"Hour: {}, Avg # Comments: {:.2f}\".format(rec[1], rec[0]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averages of comments by hour confirm that posts made between the hours of 1000-1500 are more likely to get comments.  An outlier is 0200."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
